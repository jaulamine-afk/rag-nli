# Pipeline RAG Intelligent - Am√©lioration de la Pr√©cision des R√©ponses par Filtrage Intelligent

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED)](https://www.docker.com/)
[![AWS](https://img.shields.io/badge/AWS-Deployed-FF9900)](https://aws.amazon.com/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

[English](README.md)

Syst√®me de g√©n√©ration augment√©e par r√©cup√©ration (RAG) production-ready qui filtre les informations non pertinentes avant la g√©n√©ration de r√©ponses, offrant des r√©sultats IA plus pr√©cis et fiables.

**Parfait pour :** Support client, analyse de documents juridiques, recherche dans la documentation technique, v√©rification de conformit√©

---

## Impact

Les chatbots et syst√®mes de Q&A standards souffrent souvent de probl√®mes critiques :

- ‚ùå **Hallucinations** - Donnent des r√©ponses confiantes mais incorrectes
- ‚ùå **Bruit informationnel** - M√©langent informations pertinentes et non pertinentes
- ‚ùå **√âchecs sur questions complexes** - Peinent avec les questions multi-parties

**Ce syst√®me r√©sout ces probl√®mes en :**

- ‚úÖ Filtrant le bruit avant de g√©n√©rer les r√©ponses (am√©liorations d√©montr√©es de la pr√©cision)
- ‚úÖ Validant chaque information ind√©pendamment
- ‚úÖ G√©rant les questions complexes n√©cessitant plusieurs sources

**Impact r√©el :**
- R√©duction des erreurs et du temps de r√©ponse du support client
- R√©vision de documents plus rapide pour les √©quipes juridiques et de conformit√©
- Recherche dans les bases de connaissances plus fiable
- R√©duction des co√ªts op√©rationnels gr√¢ce √† moins de r√©ponses incorrectes

---
## Fonctionnement

### Vue d'Ensemble Simple

Le syst√®me utilise une approche de filtrage intelligent en trois √©tapes :

1. **R√©cup√©ration** - Recherche de documents potentiellement pertinents via recherche vectorielle dense (FAISS)
2. **V√©rification** - L'IA valide chaque document : *"Cette information supporte-t-elle r√©ellement la r√©ponse √† la question ?"*
3. **Filtrage** - Ne conserve que les informations v√©rifi√©es et pertinentes
4. **G√©n√©ration** - Cr√©e une r√©ponse √† partir de donn√©es propres et valid√©es uniquement

### Trois Variantes de Pipeline

| Pipeline | Description | Id√©al Pour |
|----------|-------------|------------|
| **RAG Baseline** | R√©cup√©ration + g√©n√©ration standard | Questions factuelles simples |
| **RAG + NLI** | Ajoute un filtrage intelligent via inf√©rence en langage naturel | Q&A g√©n√©ral avec r√©duction du bruit |
| **RAG + NLI + Sous-Affirmations** | D√©compose les questions complexes en parties plus simples | Questions multi-parties, comparatives |

### Architecture 

<p align="center">
  <img src="docs/images/Graph_rag_nli_sub.png" alt="Architecture RAG avec NLI" width="600">
  <br>
  <em>Workflow de D√©composition en Sous-Affirmations et Filtrage par Implication NLI</em>
</p>

üìñ **Explications techniques d√©taill√©es :**
- [Explication d√©taill√©e RAG + NLI](docs/rag_nli.md)
- [Explication d√©taill√©e RAG + NLI + Sous-Affirmations](docs/rag_nli_subclaim.md)

---

## M√©triques

**√âvaluation sur le benchmark de r√©f√©rence HotpotQA :**

| M√©trique | Am√©lioration vs Baseline |
|----------|--------------------------|
| **Pr√©cision des R√©ponses (Exact Match)** | **+16%** |
| **Qualit√© des R√©ponses (Score F1)** | **+10%** |

Ces am√©liorations proviennent de la **r√©duction intelligente du bruit de r√©cup√©ration**, pas simplement de plus de puissance de calcul.

üìà [Voir les r√©sultats d'√©valuation d√©taill√©s](docs/evaluations.md)

---
## Agent d'Analyse

Agent de d√©bogage int√©gr√© propuls√© par Gemini qui explique les d√©cisions du pipeline en langage naturel.

**Exemple d'Analyse :**

**1. Comparaison des R√©sultats :**

<p align="center">
  <img src="docs/images/Agent_compare.png" alt="Comparaison RAG vs NLI" width="600">
</p>

L'agent montre comment la baseline √©choue (hallucination) tandis que le syst√®me filtr√© r√©ussit.

**2. Comprendre Pourquoi :**

<p align="center">
  <img src="docs/images/Agent_analysis.png" alt="Analyse Logique Agent" width="600">
</p>

L'agent explique que le module NLI a filtr√© avec succ√®s le passage "distracteur" sur Rihanna car il ne validait pas l'affirmation sur l'album "Confessions" d'Usher.

*Cet agent aide pendant le d√©veloppement √† analyser les d√©cisions du pipeline, comparer les sorties baseline vs filtr√©es, et fournit des insights actionnables pour l'optimisation du syst√®me.*

---

## D√©marrage Rapide

### 1. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

### 2. Lancer les exp√©riences

```bash
python -m scripts.run_experiments
```

Cela ex√©cutera tous les pipelines sur un sous-ensemble de HotpotQA et affichera les m√©triques d'√©valuation.

### 3. Lancer l'API

Le projet expose un service FastAPI qui donne acc√®s √† un agent d'analyse.

```bash
python -m uvicorn api.main:app --host 127.0.0.1 --port 8001
```

## Configuration de la Cl√© API (Gemini)

Certains composants (agent d'analyse) utilisent Gemini 2.5 Flash.

1. G√©n√©rez une cl√© API ici :
   [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)

2. Cr√©ez un fichier nomm√© `.env` √† la racine du projet.

3. Ajoutez votre cl√© dans le fichier `.env` :
   ```env
   GOOGLE_API_KEY=votre_cle_api_ici
   ```

---
## D√©ploiement Docker

D√©ploiement conteneuris√© pr√™t pour la production :

```bash
# Construire l'image Docker
docker build -t rag-nli-app .

# Lancer le conteneur
docker run -p 8001:8001 rag-nli-app

# Acc√©der √† l'API
curl http://localhost:8001/health
```

**D√©ploiement test√© sur :**
- D√©veloppement local (Linux/macOS/Windows)
- AWS EC2 (Ubuntu)
- Services de conteneurs cloud (compatible ECS, Cloud Run)

---

## Applications Concr√®tes

| Domaine |
|---------|
| **Support Client** |
| **Juridique & Conformit√©** |
| **Documentation Technique** |
| **Information M√©dicale** |


## Structure du Projet

```
rag-nli/
‚îÇ
‚îú‚îÄ‚îÄ rag/                 # Modules de r√©cup√©ration & g√©n√©ration
‚îú‚îÄ‚îÄ nli/                 # Mod√®le NLI et logique de filtrage
‚îú‚îÄ‚îÄ pipelines/           # Impl√©mentations des pipelines
‚îÇ   ‚îú‚îÄ‚îÄ baseline.py      # RAG standard
‚îÇ   ‚îú‚îÄ‚îÄ nli.py           # RAG + filtrage NLI
‚îÇ   ‚îî‚îÄ‚îÄ subclaim.py      # RAG + NLI + Sous-affirmations
‚îú‚îÄ‚îÄ evaluation/          # M√©triques et lanceurs d'exp√©riences
‚îú‚îÄ‚îÄ agents/              # Agent d'analyse pour le d√©bogage
‚îú‚îÄ‚îÄ api/                 # Service FastAPI
‚îú‚îÄ‚îÄ scripts/             # Scripts d'ex√©cution d'exp√©riences
‚îú‚îÄ‚îÄ data/                # Stockage des datasets
‚îú‚îÄ‚îÄ docs/                # Documentation d√©taill√©e
‚îú‚îÄ‚îÄ Dockerfile           # Configuration du conteneur
‚îî‚îÄ‚îÄ README.md
```

## Limitations & Am√©liorations

**Limitations actuelles :**
- La d√©composition en sous-affirmations utilise des heuristiques bas√©es sur des r√®gles (peut √™tre am√©lior√©e avec d√©composition apprise)
- Tous les types de questions dans HotpotQA ne b√©n√©ficient pas √©galement de la d√©composition
- √âvaluation r√©alis√©e sur CPU uniquement (pas encore de tests de significativit√© statistique)
- √âvaluation √† √©chelle proof-of-concept (d√©montre la m√©thodologie sur un sous-ensemble du benchmark)
- Focus sur la r√©duction du bruit de r√©cup√©ration, pas la pr√©vention compl√®te des hallucinations

**Am√©liorations futures :**
- G√©n√©ration de sous-affirmations apprise utilisant des LLMs
- √âvaluation acc√©l√©r√©e par GPU pour tests statistiques
- Couverture de datasets √©largie au-del√† de HotpotQA
- Mod√®les NLI fine-tun√©s pour des cas d'usage sp√©cifiques au domaine

Ces limitations sont reconnues pour souligner le r√©alisme et guider le d√©veloppement futur.

---

## Technologies 

**Technologies Principales :**
- **Python 3.10+** - Langage de programmation principal
- **FastAPI** - Framework API de production
- **Docker** - Conteneurisation

**Stack IA/ML :**
- **Hugging Face Transformers** - Mod√®les NLI et g√©n√©ration de texte
- **FAISS** - Recherche rapide de similarit√© vectorielle
- **LangChain / LangGraph** - Orchestration de pipelines

**D√©ploiement :**
- **AWS EC2** - D√©ploiement cloud test√©
- **Google Gemini** - Agent d'analyse

---

## R√©f√©rences

[1] Lu Dai, Hao Liu, Hui Xiong. "Improve Dense Passage Retrieval with Entailment Tuning." The Hong Kong University of Science and Technology, 2024.

[2] Ori Yoran, et al. "Making Retrieval-Augmented Language Models Robust to Irrelevant Context." ICLR, 2024. (Foundational work on noise filtration in RAG).

[3] Akari Asai, et al. "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection." ICLR, 2024. (Context regarding self-correction and claim support).

[4] Shahul Es, et al. "RAGAS: Automated Evaluation of Retrieval Augmented Generation." EACL, 2024. (Framework used for defining Faithfulness metrics via NLI).

[5] Nelson F. Liu, et al. "Lost in the Middle: How Language Models Use Long Contexts." TACL, 2024. (Highlights the necessity of filtering to avoid performance degradation in long contexts).

---
