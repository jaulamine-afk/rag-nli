# RAG avec NLI et D√©composition en Sous-Revendications

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED)](https://www.docker.com/)
[![AWS](https://img.shields.io/badge/AWS-Deployed-FF9900)](https://aws.amazon.com/)
[![License](https://img.shields.io/badge/License-MIT-green)](LICENSE)

[English](README.md)

Syst√®me RAG pr√™t pour la production qui filtre les informations non pertinentes avant la g√©n√©ration de r√©ponses, offrant des r√©ponses IA plus pr√©cises et fiables.

**Cas d‚Äôusage :** Support client, analyse de documents juridiques, recherche dans la documentation technique, v√©rification de conformit√©

---

## Enjeux

Les chatbots et syst√®mes de questions-r√©ponses standards souffrent souvent de probl√®mes critiques :

- ‚ùå **Hallucinations** - Donnent des r√©ponses confiantes mais incorrectes
- ‚ùå **Bruit informationnel** - M√©langent contenu pertinent et non pertinent
- ‚ùå **√âchecs sur questions complexes** - Peinent avec les questions √† plusieurs parties

**Ce syst√®me r√©sout ces probl√®mes en :**

- ‚úÖ Filtrant le bruit avant de g√©n√©rer les r√©ponses (am√©liorations d√©montr√©es de la pr√©cision)
- ‚úÖ Validant chaque √©l√©ment d'information ind√©pendamment
- ‚úÖ G√©rant les questions complexes n√©cessitant plusieurs sources

**Impact concret :**
- R√©duction des erreurs et du temps de r√©ponse du support client
- Examen plus rapide des documents pour les √©quipes juridiques et de conformit√©
- Recherche plus fiable dans les bases de connaissances
- Co√ªts op√©rationnels r√©duits gr√¢ce √† moins de r√©ponses incorrectes

---

## Applications Cl√©s

| Domaine | Impact Principal |
|---------|------------------|
| üìû Support Client | R√©solution plus rapide des tickets, r√©ponses plus fiables |
| ‚öñÔ∏è Juridique & Conformit√© | Analyse de documents plus rapide, risque juridique r√©duit |
| üìö Documentation Technique | Meilleure exp√©rience d√©veloppeur, charge de support r√©duite |
| üè• Information Sant√© | Information plus s√ªre et plus fiable |


## Aper√ßu de l'Approche

Trois pipelines sont impl√©ment√©s et compar√©s :

**Baseline RAG :** R√©cup√©ration dense (FAISS) + g√©n√©ration bas√©e sur prompts

**RAG + NLI :** Filtre les passages r√©cup√©r√©s en utilisant NLI pour ne garder que ceux qui impliquent la revendication ([d√©tails](docs/rag_nli.md))

**RAG + NLI + Sous-Revendications :** D√©compose les revendications complexes en sous-revendications, valide chacune ind√©pendamment ([d√©tails](docs/rag_nli_subclaim.md))

## Architecture du Syst√®me

Le diagramme ci-dessous illustre le pipeline principal (**RAG + NLI + Sous-Revendications**). Il d√©taille comment les requ√™tes complexes sont d√©compos√©es et comment le mod√®le NLI agit comme un gardien s√©mantique pour filtrer le bruit avant la g√©n√©ration.

<p align="center">
  <img src="docs/images/Graph_rag_nli_sub.png" alt="Architecture RAG avec NLI" width="600">
  <br>
  <em>(Figure : Flux de travail de la D√©composition en Sous-Revendications et du Filtrage par Implication NLI)</em>
</p>

## √âvaluation

Les exp√©riences ont √©t√© men√©es sur HotpotQA (configuration avec distracteurs).

**M√©triques utilis√©es :**

- Exact Match
- F1
- BERTScore (Pr√©cision / Rappel / F1)

| M√©trique | Am√©lioration vs Baseline |
|----------|--------------------------|
| **Pr√©cision des R√©ponses (Exact Match)** | **+16%** |
| **Qualit√© des R√©ponses (Score F1)** | **+10%** |

**R√©sultats cl√©s :**  
Avec notre pipeline le plus avanc√© (**RAG + NLI + Sous-Revendications**), nous avons observ√© jusqu'√† **+16% d'am√©lioration en Exact Match** et **+10% en F1** par rapport √† une baseline RAG standard, selon le mod√®le et la configuration Top-K.


üìà [Voir les r√©sultats d'√©valuation d√©taill√©s](docs/evaluations.md)

---

## Agent d'Analyse

Agent de d√©bogage int√©gr√© propuls√© par Gemini qui explique les d√©cisions du pipeline en langage clair.

**Exemple d'Analyse :**

**1. Comparaison des R√©sultats :**

<p align="center">
  <img src="docs/images/Agent_compare.png" alt="Comparaison RAG vs NLI" width="600">
</p>

L'agent montre comment la baseline √©choue (hallucination) tandis que le syst√®me filtr√© r√©ussit.

**2. Comprendre Pourquoi :**

<p align="center">
  <img src="docs/images/Agent_analysis.png" alt="Analyse Logique Agent" width="600">
</p>

L'agent explique que le module NLI a filtr√© avec succ√®s le passage "distracteur" sur Rihanna car il n'impliquait pas la revendication sur l'album "Confessions" d'Usher.

*Cet agent aide pendant le d√©veloppement √† analyser les d√©cisions du pipeline, comparer les sorties baseline vs filtr√©es, et fournit des informations exploitables pour l'ajustement du syst√®me.*

---

## Structure du Projet

```
rag-nli/
‚îÇ
‚îú‚îÄ‚îÄ rag/                 # R√©cup√©ration & g√©n√©ration
‚îú‚îÄ‚îÄ nli/                 # Mod√®le NLI et logique de filtrage
‚îú‚îÄ‚îÄ pipelines/           # RAG / RAG+NLI / RAG+NLI+Subclaim
‚îú‚îÄ‚îÄ evaluation/          # M√©triques et exp√©riences
‚îú‚îÄ‚îÄ agents/              # Agent d'analyse
‚îú‚îÄ‚îÄ api/                 # Service FastAPI
‚îú‚îÄ‚îÄ scripts/             # Ex√©cuteurs d'exp√©riences
‚îú‚îÄ‚îÄ data/
‚îú‚îÄ‚îÄ docs/
‚îî‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ README.md

```

## Ex√©cution du Projet

### 1. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

### 2. Ex√©cuter les exp√©riences

```bash
python -m scripts.run_experiments
```

Cela ex√©cutera tous les pipelines sur un sous-ensemble de HotpotQA et affichera les m√©triques d'√©valuation.

### 3. Ex√©cuter l'API

Le projet expose un service FastAPI pour les questions-r√©ponses.

```bash
python -m uvicorn api.main:app --host 127.0.0.1 --port 8001
```

## Configuration de la Cl√© API (Gemini)

Certains composants (agent d'analyse) utilisent Gemini 2.5 Flash.

1. G√©n√©rez une cl√© API ici :
   [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)

2. Cr√©ez un fichier nomm√© `.env` √† la racine du projet.

3. Ajoutez votre cl√© dans le fichier `.env` :
   ```env
   GOOGLE_API_KEY=votre_cl√©_api_ici
   


## Optionnel : D√©ploiement Docker

Le projet peut √©galement √™tre conteneuris√© en utilisant Docker pour faciliter le d√©ploiement et la reproductibilit√©.

Un Dockerfile est fourni pour :

- installer les d√©pendances,
- exposer le service FastAPI,
- ex√©cuter l'application dans un environnement reproductible.

**Exemples de commandes :**

```bash
docker build -t rag-nli-app .
docker run -p 8001:8001 rag-nli-app
```

Cette configuration a √©t√© test√©e localement et d√©ploy√©e sur une instance AWS EC2 (Ubuntu).

## Limitations

- La d√©composition en sous-revendications est bas√©e sur des r√®gles et heuristique
- Toutes les revendications dans HotpotQA ne sont pas d√©composables
- Pas de tests de significativit√© statistique (configuration CPU uniquement)
- L'accent est mis sur la r√©duction du bruit de r√©cup√©ration, pas sur la pr√©vention compl√®te des hallucinations

Ces limitations sont discut√©es de mani√®re transparente pour souligner le r√©alisme et la reproductibilit√©.

## Technologies

- Python
- Hugging Face
- FAISS
- FastAPI
- LangChain / LangGraph
- Docker
- AWS
- Gemini (Google GenAI)

## R√©f√©rences

[1] Lu Dai, Hao Liu, Hui Xiong. "Improve Dense Passage Retrieval with Entailment Tuning." The Hong Kong University of Science and Technology, 2024.

[2] Ori Yoran, et al. "Making Retrieval-Augmented Language Models Robust to Irrelevant Context." ICLR, 2024. (Travail fondamental sur la filtration du bruit dans RAG).

[3] Akari Asai, et al. "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection." ICLR, 2024. (Contexte concernant l'auto-correction et le support des revendications).

[4] Shahul Es, et al. "RAGAS: Automated Evaluation of Retrieval Augmented Generation." EACL, 2024. (Framework utilis√© pour d√©finir les m√©triques de Fid√©lit√© via NLI).

[5] Nelson F. Liu, et al. "Lost in the Middle: How Language Models Use Long Contexts." TACL, 2024. (Souligne la n√©cessit√© du filtrage pour √©viter la d√©gradation des performances dans les contextes longs).
